{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5e3e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ebf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714ceb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_valid_s = scaler.transform(X_valid)\n",
    "X_test_s  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3286a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888553f9",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcd891aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.01, 0.1, 1, 5, 10, 50]\n",
    "best_lr, best_acc, best_C = None, 0, None\n",
    "\n",
    "for C in C_values:\n",
    "    lr = LogisticRegression(C=C, max_iter=1000, random_state=random_state)\n",
    "    lr.fit(X_train_s, y_train)\n",
    "    acc = lr.score(X_valid_s, y_valid)\n",
    "    if acc > best_acc:\n",
    "        best_C = C\n",
    "        best_acc = acc\n",
    "        best_lr = LogisticRegression(C=C, max_iter=1000, random_state=random_state)\n",
    "\n",
    "X_train_full_s = scaler.fit_transform(X_temp)\n",
    "best_lr.fit(X_train_full_s, y_temp)\n",
    "print(\"test accuracy:\", best_lr.score(X_test_s, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea43a6",
   "metadata": {},
   "source": [
    "Dicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7be2c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree test accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "depths = [3, 5, 8, 12, None]\n",
    "best_tree, best_acc, best_depth = None, 0, None\n",
    "\n",
    "\n",
    "for d in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=d, random_state=random_state+1)\n",
    "    tree.fit(X_train, y_train)\n",
    "    acc = tree.score(X_valid, y_valid)\n",
    "    if acc > best_acc:\n",
    "        best_depth = d\n",
    "        best_tree = DecisionTreeClassifier(max_depth=d, random_state=random_state+1)\n",
    "        best_acc = acc\n",
    "\n",
    "best_tree.fit(X_temp, y_temp)\n",
    "print(\"Decision Tree test accuracy:\", best_tree.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3bf897",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "681a3d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 3, 5, 7, 9, 11]\n",
    "best_knn, best_acc, best_k = None, 0, None\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_s, y_train)\n",
    "    acc = knn.score(X_valid_s, y_valid)\n",
    "    if acc > best_acc:\n",
    "        best_k = k\n",
    "        best_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        best_acc = acc\n",
    "\n",
    "best_knn.fit(X_train_full_s, y_temp)\n",
    "print(\"test accuracy:\", best_knn.score(X_test_s, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feae9a5",
   "metadata": {},
   "source": [
    "Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5e726d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-dl/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=(32,), solver=sgd, lr=0.001, val_acc=0.9444\n",
      "h=(32,), solver=sgd, lr=0.01, val_acc=0.9694\n",
      "h=(32,), solver=adam, lr=0.001, val_acc=0.9722\n",
      "h=(32,), solver=adam, lr=0.01, val_acc=0.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-dl/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=(64,), solver=sgd, lr=0.001, val_acc=0.9444\n",
      "h=(64,), solver=sgd, lr=0.01, val_acc=0.9583\n",
      "h=(64,), solver=adam, lr=0.001, val_acc=0.9750\n",
      "h=(64,), solver=adam, lr=0.01, val_acc=0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-dl/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=(128,), solver=sgd, lr=0.001, val_acc=0.9639\n",
      "h=(128,), solver=sgd, lr=0.01, val_acc=0.9694\n",
      "h=(128,), solver=adam, lr=0.001, val_acc=0.9833\n",
      "h=(128,), solver=adam, lr=0.01, val_acc=0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-dl/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=(64, 32), solver=sgd, lr=0.001, val_acc=0.9389\n",
      "h=(64, 32), solver=sgd, lr=0.01, val_acc=0.9639\n",
      "h=(64, 32), solver=adam, lr=0.001, val_acc=0.9667\n",
      "h=(64, 32), solver=adam, lr=0.01, val_acc=0.9639\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "hidden_sizes = [(32,), (64,), (128,), (64, 32)]\n",
    "solvers = [\"sgd\", \"adam\"]\n",
    "lrs = [1e-3, 1e-2]\n",
    "\n",
    "best_mlp = None\n",
    "best_val_acc = -1.0\n",
    "\n",
    "for h, solver, lr in product(hidden_sizes, solvers, lrs):\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=h,\n",
    "        solver=solver,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=300,\n",
    "        random_state=42,\n",
    "    )\n",
    "    mlp.fit(X_train_s, y_train)\n",
    "    val_acc = mlp.score(X_valid_s, y_valid)\n",
    "\n",
    "    print(f\"h={h}, solver={solver}, lr={lr}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_mlp = mlp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53666683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "test_acc = best_mlp.score(X_test_s, y_test)\n",
    "print(\"Final test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fda5787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluation on TEST set \n",
      "\n",
      "Model: LogReg\n",
      "Accuracy: 0.975\n",
      "Recall per class (labels 0..9):\n",
      "  class 0: 1.0000\n",
      "  class 1: 0.8889\n",
      "  class 2: 1.0000\n",
      "  class 3: 1.0000\n",
      "  class 4: 1.0000\n",
      "  class 5: 1.0000\n",
      "  class 6: 0.9722\n",
      "  class 7: 1.0000\n",
      "  class 8: 0.9143\n",
      "  class 9: 0.9722\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.825\n",
      "Recall per class (labels 0..9):\n",
      "  class 0: 0.9444\n",
      "  class 1: 0.6944\n",
      "  class 2: 0.8000\n",
      "  class 3: 0.7838\n",
      "  class 4: 0.8611\n",
      "  class 5: 0.9730\n",
      "  class 6: 0.8611\n",
      "  class 7: 0.8611\n",
      "  class 8: 0.6571\n",
      "  class 9: 0.8056\n",
      "\n",
      "Model: kNN\n",
      "Accuracy: 0.9694444444444444\n",
      "Recall per class (labels 0..9):\n",
      "  class 0: 1.0000\n",
      "  class 1: 0.9722\n",
      "  class 2: 0.9714\n",
      "  class 3: 1.0000\n",
      "  class 4: 0.9444\n",
      "  class 5: 1.0000\n",
      "  class 6: 1.0000\n",
      "  class 7: 1.0000\n",
      "  class 8: 0.8857\n",
      "  class 9: 0.9167\n",
      "\n",
      "Model: MLP\n",
      "Accuracy: 0.9777777777777777\n",
      "Recall per class (labels 0..9):\n",
      "  class 0: 0.9722\n",
      "  class 1: 0.9167\n",
      "  class 2: 1.0000\n",
      "  class 3: 0.9730\n",
      "  class 4: 1.0000\n",
      "  class 5: 1.0000\n",
      "  class 6: 1.0000\n",
      "  class 7: 1.0000\n",
      "  class 8: 0.9143\n",
      "  class 9: 1.0000\n"
     ]
    }
   ],
   "source": [
    "best_models = {\n",
    "    \"LogReg\": (best_lr,  X_test_s),\n",
    "    \"DecisionTree\": (best_tree, X_test),\n",
    "    \"kNN\": (best_knn, X_test_s),\n",
    "    \"MLP\": (best_mlp, X_test_s),\n",
    "}\n",
    "\n",
    "print(\" Evaluation on TEST set \")\n",
    "for name, (model, Xte) in best_models.items():\n",
    "    y_pred = model.predict(Xte)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    recalls = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Recall per class (labels 0..9):\")\n",
    "    for label, r in enumerate(recalls):\n",
    "        print(f\"  class {label}: {r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
